{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e1b39f-da91-4ee2-8491-474b2612aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85c1c3f-943e-40b6-9188-c834e2d46264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rice data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2c9dab-be93-458e-8232-4dc95419c264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>ALLdaub4L</th>\n",
       "      <th>ALLdaub4a</th>\n",
       "      <th>ALLdaub4b</th>\n",
       "      <th>ALLdaub4Y</th>\n",
       "      <th>ALLdaub4Cb</th>\n",
       "      <th>ALLdaub4Cr</th>\n",
       "      <th>ALLdaub4XX</th>\n",
       "      <th>ALLdaub4YY</th>\n",
       "      <th>ALLdaub4ZZ</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7805</td>\n",
       "      <td>437.915</td>\n",
       "      <td>209.8215</td>\n",
       "      <td>48.0221</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>99.6877</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>7985</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>4.3693</td>\n",
       "      <td>...</td>\n",
       "      <td>113.9924</td>\n",
       "      <td>65.0610</td>\n",
       "      <td>59.5989</td>\n",
       "      <td>104.8552</td>\n",
       "      <td>67.8779</td>\n",
       "      <td>63.0828</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7503</td>\n",
       "      <td>340.757</td>\n",
       "      <td>138.3361</td>\n",
       "      <td>69.8417</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>97.7400</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>7767</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>...</td>\n",
       "      <td>105.7055</td>\n",
       "      <td>64.3685</td>\n",
       "      <td>62.2084</td>\n",
       "      <td>96.8375</td>\n",
       "      <td>65.5371</td>\n",
       "      <td>63.5832</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>0.3641</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5124</td>\n",
       "      <td>314.617</td>\n",
       "      <td>141.9803</td>\n",
       "      <td>46.5784</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>80.7718</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5271</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>3.0482</td>\n",
       "      <td>...</td>\n",
       "      <td>109.7155</td>\n",
       "      <td>62.6423</td>\n",
       "      <td>58.7439</td>\n",
       "      <td>100.2352</td>\n",
       "      <td>68.9753</td>\n",
       "      <td>59.8342</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>0.4448</td>\n",
       "      <td>Jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7990</td>\n",
       "      <td>437.085</td>\n",
       "      <td>201.4386</td>\n",
       "      <td>51.2245</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>100.8622</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>8272</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>3.9325</td>\n",
       "      <td>...</td>\n",
       "      <td>116.5405</td>\n",
       "      <td>64.9069</td>\n",
       "      <td>60.2562</td>\n",
       "      <td>107.2560</td>\n",
       "      <td>67.3298</td>\n",
       "      <td>63.2237</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7433</td>\n",
       "      <td>342.893</td>\n",
       "      <td>140.3350</td>\n",
       "      <td>68.3927</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>97.2830</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>7561</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>2.0519</td>\n",
       "      <td>...</td>\n",
       "      <td>107.7502</td>\n",
       "      <td>64.7071</td>\n",
       "      <td>61.3549</td>\n",
       "      <td>98.8704</td>\n",
       "      <td>66.2048</td>\n",
       "      <td>63.5378</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  SOLIDITY  \\\n",
       "0  7805    437.915    209.8215     48.0221        0.9735   99.6877    0.9775   \n",
       "1  7503    340.757    138.3361     69.8417        0.8632   97.7400    0.9660   \n",
       "2  5124    314.617    141.9803     46.5784        0.9447   80.7718    0.9721   \n",
       "3  7990    437.085    201.4386     51.2245        0.9671  100.8622    0.9659   \n",
       "4  7433    342.893    140.3350     68.3927        0.8732   97.2830    0.9831   \n",
       "\n",
       "   CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  ALLdaub4L  ALLdaub4a  ALLdaub4b  \\\n",
       "0         7985  0.3547        4.3693  ...   113.9924    65.0610    59.5989   \n",
       "1         7767  0.6637        1.9807  ...   105.7055    64.3685    62.2084   \n",
       "2         5271  0.4760        3.0482  ...   109.7155    62.6423    58.7439   \n",
       "3         8272  0.6274        3.9325  ...   116.5405    64.9069    60.2562   \n",
       "4         7561  0.6006        2.0519  ...   107.7502    64.7071    61.3549   \n",
       "\n",
       "   ALLdaub4Y  ALLdaub4Cb  ALLdaub4Cr  ALLdaub4XX  ALLdaub4YY  ALLdaub4ZZ  \\\n",
       "0   104.8552     67.8779     63.0828      0.3673      0.3793      0.4733   \n",
       "1    96.8375     65.5371     63.5832      0.3014      0.3144      0.3641   \n",
       "2   100.2352     68.9753     59.8342      0.3233      0.3445      0.4448   \n",
       "3   107.2560     67.3298     63.2237      0.3880      0.4020      0.4904   \n",
       "4    98.8704     66.2048     63.5378      0.3184      0.3303      0.3928   \n",
       "\n",
       "     CLASS  \n",
       "0  Basmati  \n",
       "1  Arborio  \n",
       "2  Jasmine  \n",
       "3  Basmati  \n",
       "4  Arborio  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ab28cd-6f11-4726-b695-62b3f14887ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:,0:16]\n",
    "df1[\"CLASS\"] = df[\"CLASS\"]\n",
    "df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3aa2db-40af-42b0-9d5c-9f5f15172601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37893170-ddd7-46fe-a74d-967f3b3bb785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "Basmati      15000\n",
       "Arborio      15000\n",
       "Jasmine      15000\n",
       "Ipsala       15000\n",
       "Karacadag    15000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CLASS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad778277-8b3c-4f69-8b8e-287b8c9cfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AREA           75000 non-null  int64  \n",
      " 1   PERIMETER      75000 non-null  float64\n",
      " 2   MAJOR_AXIS     75000 non-null  float64\n",
      " 3   MINOR_AXIS     75000 non-null  float64\n",
      " 4   ECCENTRICITY   75000 non-null  float64\n",
      " 5   EQDIASQ        75000 non-null  float64\n",
      " 6   SOLIDITY       75000 non-null  float64\n",
      " 7   CONVEX_AREA    75000 non-null  int64  \n",
      " 8   EXTENT         75000 non-null  float64\n",
      " 9   ASPECT_RATIO   75000 non-null  float64\n",
      " 10  ROUNDNESS      75000 non-null  float64\n",
      " 11  COMPACTNESS    75000 non-null  float64\n",
      " 12  SHAPEFACTOR_1  75000 non-null  float64\n",
      " 13  SHAPEFACTOR_2  75000 non-null  float64\n",
      " 14  SHAPEFACTOR_3  75000 non-null  float64\n",
      " 15  SHAPEFACTOR_4  75000 non-null  float64\n",
      " 16  CLASS          75000 non-null  object \n",
      "dtypes: float64(14), int64(2), object(1)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafeae6f-957e-4f69-be65-5729bac65755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>ROUNDNESS</th>\n",
       "      <th>COMPACTNESS</th>\n",
       "      <th>SHAPEFACTOR_1</th>\n",
       "      <th>SHAPEFACTOR_2</th>\n",
       "      <th>SHAPEFACTOR_3</th>\n",
       "      <th>SHAPEFACTOR_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8379.197507</td>\n",
       "      <td>378.169453</td>\n",
       "      <td>161.805540</td>\n",
       "      <td>66.829335</td>\n",
       "      <td>0.886077</td>\n",
       "      <td>101.731251</td>\n",
       "      <td>0.975896</td>\n",
       "      <td>8584.862320</td>\n",
       "      <td>0.633226</td>\n",
       "      <td>2.597063</td>\n",
       "      <td>0.732505</td>\n",
       "      <td>0.646079</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.429692</td>\n",
       "      <td>0.985509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3119.209274</td>\n",
       "      <td>70.597008</td>\n",
       "      <td>36.461005</td>\n",
       "      <td>16.689269</td>\n",
       "      <td>0.071906</td>\n",
       "      <td>17.874070</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>3189.298025</td>\n",
       "      <td>0.123795</td>\n",
       "      <td>0.968982</td>\n",
       "      <td>0.138637</td>\n",
       "      <td>0.110787</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.141146</td>\n",
       "      <td>0.007280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3929.000000</td>\n",
       "      <td>261.040000</td>\n",
       "      <td>96.968300</td>\n",
       "      <td>34.673000</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>70.728800</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6259.000000</td>\n",
       "      <td>316.431500</td>\n",
       "      <td>132.623500</td>\n",
       "      <td>49.650200</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>89.270400</td>\n",
       "      <td>0.970900</td>\n",
       "      <td>6385.000000</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>1.876100</td>\n",
       "      <td>0.620600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7345.000000</td>\n",
       "      <td>351.261000</td>\n",
       "      <td>149.343950</td>\n",
       "      <td>69.183900</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>96.705500</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>7532.000000</td>\n",
       "      <td>0.655800</td>\n",
       "      <td>2.153200</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>0.677100</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>0.986400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8901.000000</td>\n",
       "      <td>444.986000</td>\n",
       "      <td>197.462025</td>\n",
       "      <td>75.814125</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>106.457100</td>\n",
       "      <td>0.982200</td>\n",
       "      <td>9153.000000</td>\n",
       "      <td>0.727800</td>\n",
       "      <td>3.228700</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.526100</td>\n",
       "      <td>0.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21019.000000</td>\n",
       "      <td>593.698000</td>\n",
       "      <td>255.647200</td>\n",
       "      <td>113.441100</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>163.591600</td>\n",
       "      <td>0.992100</td>\n",
       "      <td>21633.000000</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>6.179500</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.879900</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AREA     PERIMETER    MAJOR_AXIS    MINOR_AXIS  ECCENTRICITY  \\\n",
       "count  75000.000000  75000.000000  75000.000000  75000.000000  75000.000000   \n",
       "mean    8379.197507    378.169453    161.805540     66.829335      0.886077   \n",
       "std     3119.209274     70.597008     36.461005     16.689269      0.071906   \n",
       "min     3929.000000    261.040000     96.968300     34.673000      0.627700   \n",
       "25%     6259.000000    316.431500    132.623500     49.650200      0.846100   \n",
       "50%     7345.000000    351.261000    149.343950     69.183900      0.885600   \n",
       "75%     8901.000000    444.986000    197.462025     75.814125      0.950800   \n",
       "max    21019.000000    593.698000    255.647200    113.441100      0.986800   \n",
       "\n",
       "            EQDIASQ      SOLIDITY   CONVEX_AREA        EXTENT  ASPECT_RATIO  \\\n",
       "count  75000.000000  75000.000000  75000.000000  75000.000000  75000.000000   \n",
       "mean     101.731251      0.975896   8584.862320      0.633226      2.597063   \n",
       "std       17.874070      0.007966   3189.298025      0.123795      0.968982   \n",
       "min       70.728800      0.877500   4032.000000      0.278800      1.284500   \n",
       "25%       89.270400      0.970900   6385.000000      0.561000      1.876100   \n",
       "50%       96.705500      0.976400   7532.000000      0.655800      2.153200   \n",
       "75%      106.457100      0.982200   9153.000000      0.727800      3.228700   \n",
       "max      163.591600      0.992100  21633.000000      0.901700      6.179500   \n",
       "\n",
       "          ROUNDNESS   COMPACTNESS  SHAPEFACTOR_1  SHAPEFACTOR_2  \\\n",
       "count  75000.000000  75000.000000   75000.000000   75000.000000   \n",
       "mean       0.732505      0.646079       0.020619       0.008407   \n",
       "std        0.138637      0.110787       0.005287       0.001903   \n",
       "min        0.392500      0.400600       0.011300       0.005100   \n",
       "25%        0.620600      0.551100       0.017000       0.006600   \n",
       "50%        0.775400      0.677100       0.018600       0.008700   \n",
       "75%        0.834500      0.725300       0.026200       0.009700   \n",
       "max        0.980000      0.879900       0.036900       0.013500   \n",
       "\n",
       "       SHAPEFACTOR_3  SHAPEFACTOR_4  \n",
       "count   75000.000000   75000.000000  \n",
       "mean        0.429692       0.985509  \n",
       "std         0.141146       0.007280  \n",
       "min         0.160500       0.896200  \n",
       "25%         0.303700       0.981600  \n",
       "50%         0.458500       0.986400  \n",
       "75%         0.526100       0.990700  \n",
       "max         0.774300       0.999000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44be88a6-6d31-454f-bfe8-91a0b277bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f82cd5-e094-4560-a546-67575be0007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637293d9-a9e2-4a0f-8b02-26c116de4152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>ROUNDNESS</th>\n",
       "      <th>COMPACTNESS</th>\n",
       "      <th>SHAPEFACTOR_1</th>\n",
       "      <th>SHAPEFACTOR_2</th>\n",
       "      <th>SHAPEFACTOR_3</th>\n",
       "      <th>SHAPEFACTOR_4</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7805</td>\n",
       "      <td>437.915</td>\n",
       "      <td>209.8215</td>\n",
       "      <td>48.0221</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>99.6877</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>7985</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>4.3693</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7503</td>\n",
       "      <td>340.757</td>\n",
       "      <td>138.3361</td>\n",
       "      <td>69.8417</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>97.7400</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>7767</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5124</td>\n",
       "      <td>314.617</td>\n",
       "      <td>141.9803</td>\n",
       "      <td>46.5784</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>80.7718</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5271</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>3.0482</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>Jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7990</td>\n",
       "      <td>437.085</td>\n",
       "      <td>201.4386</td>\n",
       "      <td>51.2245</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>100.8622</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>8272</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>3.9325</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.5007</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7433</td>\n",
       "      <td>342.893</td>\n",
       "      <td>140.3350</td>\n",
       "      <td>68.3927</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>97.2830</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>7561</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>2.0519</td>\n",
       "      <td>0.7944</td>\n",
       "      <td>0.6932</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>5551</td>\n",
       "      <td>285.911</td>\n",
       "      <td>114.1695</td>\n",
       "      <td>62.9079</td>\n",
       "      <td>0.8345</td>\n",
       "      <td>84.0699</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>5638</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>1.8149</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>7696</td>\n",
       "      <td>322.703</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>81.1375</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>98.9892</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>7799</td>\n",
       "      <td>0.7309</td>\n",
       "      <td>1.4961</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.8155</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>Karacadag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>7579</td>\n",
       "      <td>339.295</td>\n",
       "      <td>136.3125</td>\n",
       "      <td>71.2866</td>\n",
       "      <td>0.8524</td>\n",
       "      <td>98.2338</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>7730</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>1.9122</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.5193</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>15174</td>\n",
       "      <td>489.502</td>\n",
       "      <td>200.9486</td>\n",
       "      <td>97.6282</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>138.9969</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>15537</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>2.0583</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>Ipsala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>12931</td>\n",
       "      <td>452.635</td>\n",
       "      <td>185.5138</td>\n",
       "      <td>90.2651</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>128.3131</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>13249</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>2.0552</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>Ipsala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "0       7805    437.915    209.8215     48.0221        0.9735   99.6877   \n",
       "1       7503    340.757    138.3361     69.8417        0.8632   97.7400   \n",
       "2       5124    314.617    141.9803     46.5784        0.9447   80.7718   \n",
       "3       7990    437.085    201.4386     51.2245        0.9671  100.8622   \n",
       "4       7433    342.893    140.3350     68.3927        0.8732   97.2830   \n",
       "...      ...        ...         ...         ...           ...       ...   \n",
       "74995   5551    285.911    114.1695     62.9079        0.8345   84.0699   \n",
       "74996   7696    322.703    121.3900     81.1375        0.7438   98.9892   \n",
       "74997   7579    339.295    136.3125     71.2866        0.8524   98.2338   \n",
       "74998  15174    489.502    200.9486     97.6282        0.8740  138.9969   \n",
       "74999  12931    452.635    185.5138     90.2651        0.8736  128.3131   \n",
       "\n",
       "       SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ROUNDNESS  COMPACTNESS  \\\n",
       "0        0.9775         7985  0.3547        4.3693     0.5114       0.4751   \n",
       "1        0.9660         7767  0.6637        1.9807     0.8120       0.7065   \n",
       "2        0.9721         5271  0.4760        3.0482     0.6505       0.5689   \n",
       "3        0.9659         8272  0.6274        3.9325     0.5256       0.5007   \n",
       "4        0.9831         7561  0.6006        2.0519     0.7944       0.6932   \n",
       "...         ...          ...     ...           ...        ...          ...   \n",
       "74995    0.9846         5638  0.6418        1.8149     0.8533       0.7364   \n",
       "74996    0.9868         7799  0.7309        1.4961     0.9287       0.8155   \n",
       "74997    0.9805         7730  0.6399        1.9122     0.8273       0.7207   \n",
       "74998    0.9766        15537  0.7903        2.0583     0.7958       0.6917   \n",
       "74999    0.9760        13249  0.7640        2.0552     0.7931       0.6917   \n",
       "\n",
       "       SHAPEFACTOR_1  SHAPEFACTOR_2  SHAPEFACTOR_3  SHAPEFACTOR_4      CLASS  \n",
       "0             0.0269         0.0062         0.2257         0.9863    Basmati  \n",
       "1             0.0184         0.0093         0.4992         0.9888    Arborio  \n",
       "2             0.0277         0.0091         0.3236         0.9865    Jasmine  \n",
       "3             0.0252         0.0064         0.2507         0.9859    Basmati  \n",
       "4             0.0189         0.0092         0.4806         0.9860    Arborio  \n",
       "...              ...            ...            ...            ...        ...  \n",
       "74995         0.0206         0.0113         0.5422         0.9841    Arborio  \n",
       "74996         0.0158         0.0105         0.6650         0.9949  Karacadag  \n",
       "74997         0.0180         0.0094         0.5193         0.9931    Arborio  \n",
       "74998         0.0132         0.0064         0.4785         0.9848     Ipsala  \n",
       "74999         0.0143         0.0070         0.4784         0.9832     Ipsala  \n",
       "\n",
       "[75000 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f14884-4361-4576-b260-fa86e4b5a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(df)\n",
    "df = pd.DataFrame(df)\n",
    "X = df.drop(columns = [16])\n",
    "y = df[16]\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a576792-2434-4582-bbcb-3a9aca0264b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "MLP: Acc=0.9787, Err=0.0213, Prec=0.9787, Rec=0.9787, F1=0.9787, Kappa=0.9733\n",
      "Random Forest: Acc=0.9787, Err=0.0213, Prec=0.9787, Rec=0.9787, F1=0.9787, Kappa=0.9733\n",
      "SVM: Acc=0.9751, Err=0.0249, Prec=0.9751, Rec=0.9751, F1=0.9751, Kappa=0.9688\n",
      "KNN: Acc=0.9784, Err=0.0216, Prec=0.9784, Rec=0.9784, F1=0.9784, Kappa=0.9730\n",
      "Logistic Regression: Acc=0.9749, Err=0.0251, Prec=0.9750, Rec=0.9749, F1=0.9749, Kappa=0.9687\n",
      "Decision Tree: Acc=0.9705, Err=0.0295, Prec=0.9705, Rec=0.9705, F1=0.9705, Kappa=0.9632\n",
      "--------------------------------------------------\n",
      "Fold 2 :\n",
      "MLP: Acc=0.9836, Err=0.0164, Prec=0.9837, Rec=0.9836, F1=0.9836, Kappa=0.9795\n",
      "Random Forest: Acc=0.9823, Err=0.0177, Prec=0.9823, Rec=0.9823, F1=0.9823, Kappa=0.9778\n",
      "SVM: Acc=0.9803, Err=0.0197, Prec=0.9803, Rec=0.9803, F1=0.9803, Kappa=0.9753\n",
      "KNN: Acc=0.9839, Err=0.0161, Prec=0.9839, Rec=0.9839, F1=0.9839, Kappa=0.9798\n",
      "Logistic Regression: Acc=0.9800, Err=0.0200, Prec=0.9800, Rec=0.9800, F1=0.9800, Kappa=0.9750\n",
      "Decision Tree: Acc=0.9700, Err=0.0300, Prec=0.9700, Rec=0.9700, F1=0.9700, Kappa=0.9625\n",
      "--------------------------------------------------\n",
      "Fold 3 :\n",
      "MLP: Acc=0.9821, Err=0.0179, Prec=0.9822, Rec=0.9821, F1=0.9821, Kappa=0.9777\n",
      "Random Forest: Acc=0.9789, Err=0.0211, Prec=0.9790, Rec=0.9789, F1=0.9789, Kappa=0.9737\n",
      "SVM: Acc=0.9772, Err=0.0228, Prec=0.9773, Rec=0.9772, F1=0.9772, Kappa=0.9715\n",
      "KNN: Acc=0.9791, Err=0.0209, Prec=0.9791, Rec=0.9791, F1=0.9791, Kappa=0.9738\n",
      "Logistic Regression: Acc=0.9765, Err=0.0235, Prec=0.9766, Rec=0.9765, F1=0.9766, Kappa=0.9707\n",
      "Decision Tree: Acc=0.9717, Err=0.0283, Prec=0.9718, Rec=0.9717, F1=0.9717, Kappa=0.9647\n",
      "--------------------------------------------------\n",
      "Fold 4 :\n",
      "MLP: Acc=0.9796, Err=0.0204, Prec=0.9797, Rec=0.9796, F1=0.9796, Kappa=0.9745\n",
      "Random Forest: Acc=0.9785, Err=0.0215, Prec=0.9786, Rec=0.9785, F1=0.9785, Kappa=0.9732\n",
      "SVM: Acc=0.9763, Err=0.0237, Prec=0.9763, Rec=0.9763, F1=0.9763, Kappa=0.9703\n",
      "KNN: Acc=0.9776, Err=0.0224, Prec=0.9776, Rec=0.9776, F1=0.9776, Kappa=0.9720\n",
      "Logistic Regression: Acc=0.9757, Err=0.0243, Prec=0.9758, Rec=0.9757, F1=0.9757, Kappa=0.9697\n",
      "Decision Tree: Acc=0.9713, Err=0.0287, Prec=0.9714, Rec=0.9713, F1=0.9713, Kappa=0.9642\n",
      "--------------------------------------------------\n",
      "Fold 5 :\n",
      "MLP: Acc=0.9819, Err=0.0181, Prec=0.9820, Rec=0.9819, F1=0.9819, Kappa=0.9773\n",
      "Random Forest: Acc=0.9797, Err=0.0203, Prec=0.9798, Rec=0.9797, F1=0.9797, Kappa=0.9747\n",
      "SVM: Acc=0.9769, Err=0.0231, Prec=0.9770, Rec=0.9769, F1=0.9769, Kappa=0.9712\n",
      "KNN: Acc=0.9811, Err=0.0189, Prec=0.9811, Rec=0.9811, F1=0.9811, Kappa=0.9763\n",
      "Logistic Regression: Acc=0.9765, Err=0.0235, Prec=0.9766, Rec=0.9765, F1=0.9765, Kappa=0.9707\n",
      "Decision Tree: Acc=0.9700, Err=0.0300, Prec=0.9700, Rec=0.9700, F1=0.9700, Kappa=0.9625\n",
      "--------------------------------------------------\n",
      "Fold 6 :\n",
      "MLP: Acc=0.9820, Err=0.0180, Prec=0.9820, Rec=0.9820, F1=0.9820, Kappa=0.9775\n",
      "Random Forest: Acc=0.9819, Err=0.0181, Prec=0.9819, Rec=0.9819, F1=0.9819, Kappa=0.9773\n",
      "SVM: Acc=0.9793, Err=0.0207, Prec=0.9794, Rec=0.9793, F1=0.9793, Kappa=0.9742\n",
      "KNN: Acc=0.9797, Err=0.0203, Prec=0.9798, Rec=0.9797, F1=0.9797, Kappa=0.9747\n",
      "Logistic Regression: Acc=0.9783, Err=0.0217, Prec=0.9784, Rec=0.9783, F1=0.9783, Kappa=0.9728\n",
      "Decision Tree: Acc=0.9728, Err=0.0272, Prec=0.9728, Rec=0.9728, F1=0.9728, Kappa=0.9660\n",
      "--------------------------------------------------\n",
      "Fold 7 :\n",
      "MLP: Acc=0.9829, Err=0.0171, Prec=0.9829, Rec=0.9829, F1=0.9829, Kappa=0.9787\n",
      "Random Forest: Acc=0.9811, Err=0.0189, Prec=0.9811, Rec=0.9811, F1=0.9811, Kappa=0.9763\n",
      "SVM: Acc=0.9788, Err=0.0212, Prec=0.9789, Rec=0.9788, F1=0.9788, Kappa=0.9735\n",
      "KNN: Acc=0.9812, Err=0.0188, Prec=0.9812, Rec=0.9812, F1=0.9812, Kappa=0.9765\n",
      "Logistic Regression: Acc=0.9780, Err=0.0220, Prec=0.9780, Rec=0.9780, F1=0.9780, Kappa=0.9725\n",
      "Decision Tree: Acc=0.9728, Err=0.0272, Prec=0.9728, Rec=0.9728, F1=0.9728, Kappa=0.9660\n",
      "--------------------------------------------------\n",
      "Fold 8 :\n",
      "MLP: Acc=0.9804, Err=0.0196, Prec=0.9805, Rec=0.9804, F1=0.9804, Kappa=0.9755\n",
      "Random Forest: Acc=0.9803, Err=0.0197, Prec=0.9803, Rec=0.9803, F1=0.9803, Kappa=0.9753\n",
      "SVM: Acc=0.9772, Err=0.0228, Prec=0.9773, Rec=0.9772, F1=0.9772, Kappa=0.9715\n",
      "KNN: Acc=0.9772, Err=0.0228, Prec=0.9773, Rec=0.9772, F1=0.9772, Kappa=0.9715\n",
      "Logistic Regression: Acc=0.9771, Err=0.0229, Prec=0.9771, Rec=0.9771, F1=0.9771, Kappa=0.9713\n",
      "Decision Tree: Acc=0.9715, Err=0.0285, Prec=0.9715, Rec=0.9715, F1=0.9715, Kappa=0.9643\n",
      "--------------------------------------------------\n",
      "Fold 9 :\n",
      "MLP: Acc=0.9793, Err=0.0207, Prec=0.9794, Rec=0.9793, F1=0.9793, Kappa=0.9742\n",
      "Random Forest: Acc=0.9803, Err=0.0197, Prec=0.9803, Rec=0.9803, F1=0.9803, Kappa=0.9753\n",
      "SVM: Acc=0.9779, Err=0.0221, Prec=0.9779, Rec=0.9779, F1=0.9779, Kappa=0.9723\n",
      "KNN: Acc=0.9792, Err=0.0208, Prec=0.9792, Rec=0.9792, F1=0.9792, Kappa=0.9740\n",
      "Logistic Regression: Acc=0.9765, Err=0.0235, Prec=0.9766, Rec=0.9765, F1=0.9765, Kappa=0.9707\n",
      "Decision Tree: Acc=0.9708, Err=0.0292, Prec=0.9708, Rec=0.9708, F1=0.9708, Kappa=0.9635\n",
      "--------------------------------------------------\n",
      "Fold 10 :\n",
      "MLP: Acc=0.9821, Err=0.0179, Prec=0.9822, Rec=0.9821, F1=0.9821, Kappa=0.9777\n",
      "Random Forest: Acc=0.9799, Err=0.0201, Prec=0.9799, Rec=0.9799, F1=0.9799, Kappa=0.9748\n",
      "SVM: Acc=0.9769, Err=0.0231, Prec=0.9769, Rec=0.9769, F1=0.9769, Kappa=0.9712\n",
      "KNN: Acc=0.9797, Err=0.0203, Prec=0.9798, Rec=0.9797, F1=0.9797, Kappa=0.9747\n",
      "Logistic Regression: Acc=0.9772, Err=0.0228, Prec=0.9772, Rec=0.9772, F1=0.9772, Kappa=0.9715\n",
      "Decision Tree: Acc=0.9700, Err=0.0300, Prec=0.9700, Rec=0.9700, F1=0.9700, Kappa=0.9625\n",
      "--------------------------------------------------\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Model               |   Avg Acc |   Avg Error |   Avg Prec |   Avg Recall |   Avg F1 |   Avg Kappa |\n",
      "+=====================+===========+=============+============+==============+==========+=============+\n",
      "| MLP                 |    0.9813 |      0.0187 |     0.9813 |       0.9813 |   0.9813 |      0.9766 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Random Forest       |    0.9801 |      0.0199 |     0.9802 |       0.9801 |   0.9801 |      0.9752 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| SVM                 |    0.9776 |      0.0224 |     0.9776 |       0.9776 |   0.9776 |      0.972  |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| KNN                 |    0.9797 |      0.0203 |     0.9797 |       0.9797 |   0.9797 |      0.9746 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Logistic Regression |    0.9771 |      0.0229 |     0.9771 |       0.9771 |   0.9771 |      0.9713 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Decision Tree       |    0.9711 |      0.0289 |     0.9712 |       0.9711 |   0.9711 |      0.9639 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "models = {\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(64, 32, 16, 8), activation='logistic', max_iter=10000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=10),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "model_metrics = {name: {\"Accuracy\": [], \"Error\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": [], \"Kappa\": []} for name in models.keys()}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"Fold {fold + 1} :\")\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        error = 1 - acc  # Error rate\n",
    "        prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "        model_metrics[name][\"Accuracy\"].append(acc)\n",
    "        model_metrics[name][\"Error\"].append(error)\n",
    "        model_metrics[name][\"Precision\"].append(prec)\n",
    "        model_metrics[name][\"Recall\"].append(rec)\n",
    "        model_metrics[name][\"F1-Score\"].append(f1)\n",
    "        model_metrics[name][\"Kappa\"].append(kappa)\n",
    "\n",
    "        print(f\"{name}: Acc={acc:.4f}, Err={error:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}, Kappa={kappa:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "table_data = [\n",
    "    [name, \n",
    "     f\"{np.mean(metrics['Accuracy']):.4f}\", \n",
    "     f\"{np.mean(metrics['Error']):.4f}\", \n",
    "     f\"{np.mean(metrics['Precision']):.4f}\", \n",
    "     f\"{np.mean(metrics['Recall']):.4f}\", \n",
    "     f\"{np.mean(metrics['F1-Score']):.4f}\", \n",
    "     f\"{np.mean(metrics['Kappa']):.4f}\"]\n",
    "    for name, metrics in model_metrics.items()\n",
    "]\n",
    "\n",
    "print(tabulate(table_data, headers=[\"Model\", \"Avg Acc\", \"Avg Error\", \"Avg Prec\", \"Avg Recall\", \"Avg F1\", \"Avg Kappa\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0833dc38-5c6f-43fd-acdd-b809a4c6fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 1 Completed\n",
      "--------------------------------------------------\n",
      "Fold 2 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 2 Completed\n",
      "--------------------------------------------------\n",
      "Fold 3 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 3 Completed\n",
      "--------------------------------------------------\n",
      "Fold 4 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 4 Completed\n",
      "--------------------------------------------------\n",
      "Fold 5 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 5 Completed\n",
      "--------------------------------------------------\n",
      "Fold 6 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 6 Completed\n",
      "--------------------------------------------------\n",
      "Fold 7 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 7 Completed\n",
      "--------------------------------------------------\n",
      "Fold 8 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 8 Completed\n",
      "--------------------------------------------------\n",
      "Fold 9 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 9 Completed\n",
      "--------------------------------------------------\n",
      "Fold 10 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 10 Completed\n",
      "--------------------------------------------------\n",
      "   Actual Class            Algorithm  Arborio  Basmati  Ipsala  Jasmine  \\\n",
      "0       Arborio                  MLP    14528        0      13       35   \n",
      "1       Arborio        Random Forest    14502        0      12       28   \n",
      "2       Arborio                  SVM    14449        0       5       37   \n",
      "3       Arborio                  KNN    14506        0       2       38   \n",
      "4       Arborio  Logistic Regression    14470        0       3       37   \n",
      "5       Arborio        Decision Tree    14362        0      26       37   \n",
      "6       Basmati                  MLP        0    14711       0      289   \n",
      "7       Basmati        Random Forest        0    14719       0      281   \n",
      "8       Basmati                  SVM        0    14616       0      384   \n",
      "9       Basmati                  KNN        1    14727       0      272   \n",
      "10      Basmati  Logistic Regression        0    14620       0      380   \n",
      "11      Basmati        Decision Tree        1    14619       0      380   \n",
      "12       Ipsala                  MLP       22        0   14940       38   \n",
      "13       Ipsala        Random Forest       22        0   14938       40   \n",
      "14       Ipsala                  SVM       27        0   14937       36   \n",
      "15       Ipsala                  KNN       38        0   14922       40   \n",
      "16       Ipsala  Logistic Regression       36        0   14931       33   \n",
      "17       Ipsala        Decision Tree       23        0   14931       46   \n",
      "18      Jasmine                  MLP       20      234      24    14721   \n",
      "19      Jasmine        Random Forest       21      261      29    14688   \n",
      "20      Jasmine                  SVM       29      266      24    14680   \n",
      "21      Jasmine                  KNN       23      287      21    14668   \n",
      "22      Jasmine  Logistic Regression       28      290      30    14651   \n",
      "23      Jasmine        Decision Tree       40      391      53    14514   \n",
      "24    Karacadag                  MLP      305        0       0        0   \n",
      "25    Karacadag        Random Forest      336        0       0        0   \n",
      "26    Karacadag                  SVM      363        0       0        0   \n",
      "27    Karacadag                  KNN      345        0       0        0   \n",
      "28    Karacadag  Logistic Regression      391        0       0        0   \n",
      "29    Karacadag        Decision Tree      589        0       0        1   \n",
      "\n",
      "    Karacadag  \n",
      "0         424  \n",
      "1         458  \n",
      "2         509  \n",
      "3         454  \n",
      "4         490  \n",
      "5         575  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          0  \n",
      "11          0  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          0  \n",
      "17          0  \n",
      "18          1  \n",
      "19          1  \n",
      "20          1  \n",
      "21          1  \n",
      "22          1  \n",
      "23          2  \n",
      "24      14695  \n",
      "25      14664  \n",
      "26      14637  \n",
      "27      14655  \n",
      "28      14609  \n",
      "29      14410  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = np.unique(y)\n",
    "conf_matrix_sum = {name: np.zeros((len(labels), len(labels))) for name in models.keys()}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"Fold {fold + 1} :\")\n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        conf_matrix_sum[name] += cm\n",
    "        print(f\"{name}\")\n",
    "\n",
    "    print(f\"Fold {fold + 1} Completed\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "conf_matrix_total = {name: cm.astype(int) for name, cm in conf_matrix_sum.items()}\n",
    "\n",
    "conf_matrix_data = []\n",
    "for i, actual in enumerate(labels):\n",
    "    for name, cm in conf_matrix_total.items():\n",
    "        row = [actual, name]\n",
    "        row.extend(cm[i])\n",
    "        conf_matrix_data.append(row)\n",
    "\n",
    "columns = [\"Actual Class\", \"Algorithm\"] + list(labels)\n",
    "df_conf_matrix = pd.DataFrame(conf_matrix_data, columns=columns)\n",
    "\n",
    "print(df_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b08c51-5d93-4933-be6e-a92163970d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|    | Actual Class   | Algorithm           |   Arborio |   Basmati |   Ipsala |   Jasmine |   Karacadag |\n",
      "+====+================+=====================+===========+===========+==========+===========+=============+\n",
      "|  0 | Arborio        | MLP                 |     14528 |         0 |       13 |        35 |         424 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  1 | Arborio        | Random Forest       |     14502 |         0 |       12 |        28 |         458 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  2 | Arborio        | SVM                 |     14449 |         0 |        5 |        37 |         509 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  3 | Arborio        | KNN                 |     14506 |         0 |        2 |        38 |         454 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  4 | Arborio        | Logistic Regression |     14470 |         0 |        3 |        37 |         490 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  5 | Arborio        | Decision Tree       |     14362 |         0 |       26 |        37 |         575 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  6 | Basmati        | MLP                 |         0 |     14711 |        0 |       289 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  7 | Basmati        | Random Forest       |         0 |     14719 |        0 |       281 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  8 | Basmati        | SVM                 |         0 |     14616 |        0 |       384 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  9 | Basmati        | KNN                 |         1 |     14727 |        0 |       272 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 10 | Basmati        | Logistic Regression |         0 |     14620 |        0 |       380 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 11 | Basmati        | Decision Tree       |         1 |     14619 |        0 |       380 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 12 | Ipsala         | MLP                 |        22 |         0 |    14940 |        38 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 13 | Ipsala         | Random Forest       |        22 |         0 |    14938 |        40 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 14 | Ipsala         | SVM                 |        27 |         0 |    14937 |        36 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 15 | Ipsala         | KNN                 |        38 |         0 |    14922 |        40 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 16 | Ipsala         | Logistic Regression |        36 |         0 |    14931 |        33 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 17 | Ipsala         | Decision Tree       |        23 |         0 |    14931 |        46 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 18 | Jasmine        | MLP                 |        20 |       234 |       24 |     14721 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 19 | Jasmine        | Random Forest       |        21 |       261 |       29 |     14688 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 20 | Jasmine        | SVM                 |        29 |       266 |       24 |     14680 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 21 | Jasmine        | KNN                 |        23 |       287 |       21 |     14668 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 22 | Jasmine        | Logistic Regression |        28 |       290 |       30 |     14651 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 23 | Jasmine        | Decision Tree       |        40 |       391 |       53 |     14514 |           2 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 24 | Karacadag      | MLP                 |       305 |         0 |        0 |         0 |       14695 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 25 | Karacadag      | Random Forest       |       336 |         0 |        0 |         0 |       14664 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 26 | Karacadag      | SVM                 |       363 |         0 |        0 |         0 |       14637 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 27 | Karacadag      | KNN                 |       345 |         0 |        0 |         0 |       14655 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 28 | Karacadag      | Logistic Regression |       391 |         0 |        0 |         0 |       14609 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 29 | Karacadag      | Decision Tree       |       589 |         0 |        0 |         1 |       14410 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(df_conf_matrix, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1170f71-f828-4d5d-ba5b-5cc4537344eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
