{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e1b39f-da91-4ee2-8491-474b2612aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85c1c3f-943e-40b6-9188-c834e2d46264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rice data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2c9dab-be93-458e-8232-4dc95419c264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>ALLdaub4L</th>\n",
       "      <th>ALLdaub4a</th>\n",
       "      <th>ALLdaub4b</th>\n",
       "      <th>ALLdaub4Y</th>\n",
       "      <th>ALLdaub4Cb</th>\n",
       "      <th>ALLdaub4Cr</th>\n",
       "      <th>ALLdaub4XX</th>\n",
       "      <th>ALLdaub4YY</th>\n",
       "      <th>ALLdaub4ZZ</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7805</td>\n",
       "      <td>437.915</td>\n",
       "      <td>209.8215</td>\n",
       "      <td>48.0221</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>99.6877</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>7985</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>4.3693</td>\n",
       "      <td>...</td>\n",
       "      <td>113.9924</td>\n",
       "      <td>65.0610</td>\n",
       "      <td>59.5989</td>\n",
       "      <td>104.8552</td>\n",
       "      <td>67.8779</td>\n",
       "      <td>63.0828</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7503</td>\n",
       "      <td>340.757</td>\n",
       "      <td>138.3361</td>\n",
       "      <td>69.8417</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>97.7400</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>7767</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>...</td>\n",
       "      <td>105.7055</td>\n",
       "      <td>64.3685</td>\n",
       "      <td>62.2084</td>\n",
       "      <td>96.8375</td>\n",
       "      <td>65.5371</td>\n",
       "      <td>63.5832</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>0.3641</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5124</td>\n",
       "      <td>314.617</td>\n",
       "      <td>141.9803</td>\n",
       "      <td>46.5784</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>80.7718</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5271</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>3.0482</td>\n",
       "      <td>...</td>\n",
       "      <td>109.7155</td>\n",
       "      <td>62.6423</td>\n",
       "      <td>58.7439</td>\n",
       "      <td>100.2352</td>\n",
       "      <td>68.9753</td>\n",
       "      <td>59.8342</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>0.4448</td>\n",
       "      <td>Jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7990</td>\n",
       "      <td>437.085</td>\n",
       "      <td>201.4386</td>\n",
       "      <td>51.2245</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>100.8622</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>8272</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>3.9325</td>\n",
       "      <td>...</td>\n",
       "      <td>116.5405</td>\n",
       "      <td>64.9069</td>\n",
       "      <td>60.2562</td>\n",
       "      <td>107.2560</td>\n",
       "      <td>67.3298</td>\n",
       "      <td>63.2237</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7433</td>\n",
       "      <td>342.893</td>\n",
       "      <td>140.3350</td>\n",
       "      <td>68.3927</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>97.2830</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>7561</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>2.0519</td>\n",
       "      <td>...</td>\n",
       "      <td>107.7502</td>\n",
       "      <td>64.7071</td>\n",
       "      <td>61.3549</td>\n",
       "      <td>98.8704</td>\n",
       "      <td>66.2048</td>\n",
       "      <td>63.5378</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  SOLIDITY  \\\n",
       "0  7805    437.915    209.8215     48.0221        0.9735   99.6877    0.9775   \n",
       "1  7503    340.757    138.3361     69.8417        0.8632   97.7400    0.9660   \n",
       "2  5124    314.617    141.9803     46.5784        0.9447   80.7718    0.9721   \n",
       "3  7990    437.085    201.4386     51.2245        0.9671  100.8622    0.9659   \n",
       "4  7433    342.893    140.3350     68.3927        0.8732   97.2830    0.9831   \n",
       "\n",
       "   CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  ALLdaub4L  ALLdaub4a  ALLdaub4b  \\\n",
       "0         7985  0.3547        4.3693  ...   113.9924    65.0610    59.5989   \n",
       "1         7767  0.6637        1.9807  ...   105.7055    64.3685    62.2084   \n",
       "2         5271  0.4760        3.0482  ...   109.7155    62.6423    58.7439   \n",
       "3         8272  0.6274        3.9325  ...   116.5405    64.9069    60.2562   \n",
       "4         7561  0.6006        2.0519  ...   107.7502    64.7071    61.3549   \n",
       "\n",
       "   ALLdaub4Y  ALLdaub4Cb  ALLdaub4Cr  ALLdaub4XX  ALLdaub4YY  ALLdaub4ZZ  \\\n",
       "0   104.8552     67.8779     63.0828      0.3673      0.3793      0.4733   \n",
       "1    96.8375     65.5371     63.5832      0.3014      0.3144      0.3641   \n",
       "2   100.2352     68.9753     59.8342      0.3233      0.3445      0.4448   \n",
       "3   107.2560     67.3298     63.2237      0.3880      0.4020      0.4904   \n",
       "4    98.8704     66.2048     63.5378      0.3184      0.3303      0.3928   \n",
       "\n",
       "     CLASS  \n",
       "0  Basmati  \n",
       "1  Arborio  \n",
       "2  Jasmine  \n",
       "3  Basmati  \n",
       "4  Arborio  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3aa2db-40af-42b0-9d5c-9f5f15172601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 107)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37893170-ddd7-46fe-a74d-967f3b3bb785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "Basmati      15000\n",
       "Arborio      15000\n",
       "Jasmine      15000\n",
       "Ipsala       15000\n",
       "Karacadag    15000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CLASS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242e8e9e-35d8-432c-8dda-f66d34f2687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"CLASS\"].replace({\"Basmati\":0,\"Arborio\":1,\"Jasmine\":2,\"Ipsala\":3,\"Karacadag\":4},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208539d4-8c11-43ee-acb4-22eb2ee055c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "Basmati      15000\n",
       "Arborio      15000\n",
       "Jasmine      15000\n",
       "Ipsala       15000\n",
       "Karacadag    15000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CLASS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad778277-8b3c-4f69-8b8e-287b8c9cfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Columns: 107 entries, AREA to CLASS\n",
      "dtypes: float64(95), int64(11), object(1)\n",
      "memory usage: 61.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafeae6f-957e-4f69-be65-5729bac65755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>ALLdaub4V</th>\n",
       "      <th>ALLdaub4L</th>\n",
       "      <th>ALLdaub4a</th>\n",
       "      <th>ALLdaub4b</th>\n",
       "      <th>ALLdaub4Y</th>\n",
       "      <th>ALLdaub4Cb</th>\n",
       "      <th>ALLdaub4Cr</th>\n",
       "      <th>ALLdaub4XX</th>\n",
       "      <th>ALLdaub4YY</th>\n",
       "      <th>ALLdaub4ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8379.197507</td>\n",
       "      <td>378.169453</td>\n",
       "      <td>161.805540</td>\n",
       "      <td>66.829335</td>\n",
       "      <td>0.886077</td>\n",
       "      <td>101.731251</td>\n",
       "      <td>0.975896</td>\n",
       "      <td>8584.862320</td>\n",
       "      <td>0.633226</td>\n",
       "      <td>2.597063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448960</td>\n",
       "      <td>111.088252</td>\n",
       "      <td>64.379443</td>\n",
       "      <td>61.461457</td>\n",
       "      <td>101.925425</td>\n",
       "      <td>66.240541</td>\n",
       "      <td>63.202088</td>\n",
       "      <td>0.341944</td>\n",
       "      <td>0.357058</td>\n",
       "      <td>0.421176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3119.209274</td>\n",
       "      <td>70.597008</td>\n",
       "      <td>36.461005</td>\n",
       "      <td>16.689269</td>\n",
       "      <td>0.071906</td>\n",
       "      <td>17.874070</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>3189.298025</td>\n",
       "      <td>0.123795</td>\n",
       "      <td>0.968982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>5.904854</td>\n",
       "      <td>1.175616</td>\n",
       "      <td>2.435635</td>\n",
       "      <td>5.436861</td>\n",
       "      <td>2.159109</td>\n",
       "      <td>1.174976</td>\n",
       "      <td>0.041921</td>\n",
       "      <td>0.047139</td>\n",
       "      <td>0.043137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3929.000000</td>\n",
       "      <td>261.040000</td>\n",
       "      <td>96.968300</td>\n",
       "      <td>34.673000</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>70.728800</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>82.300600</td>\n",
       "      <td>59.137900</td>\n",
       "      <td>53.653800</td>\n",
       "      <td>75.191800</td>\n",
       "      <td>58.323800</td>\n",
       "      <td>57.363400</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6259.000000</td>\n",
       "      <td>316.431500</td>\n",
       "      <td>132.623500</td>\n",
       "      <td>49.650200</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>89.270400</td>\n",
       "      <td>0.970900</td>\n",
       "      <td>6385.000000</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>1.876100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>106.632900</td>\n",
       "      <td>63.883800</td>\n",
       "      <td>59.465575</td>\n",
       "      <td>97.834400</td>\n",
       "      <td>64.842000</td>\n",
       "      <td>63.052800</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.391200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7345.000000</td>\n",
       "      <td>351.261000</td>\n",
       "      <td>149.343950</td>\n",
       "      <td>69.183900</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>96.705500</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>7532.000000</td>\n",
       "      <td>0.655800</td>\n",
       "      <td>2.153200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>110.770700</td>\n",
       "      <td>64.419350</td>\n",
       "      <td>61.424400</td>\n",
       "      <td>101.683700</td>\n",
       "      <td>66.291600</td>\n",
       "      <td>63.522050</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.353300</td>\n",
       "      <td>0.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8901.000000</td>\n",
       "      <td>444.986000</td>\n",
       "      <td>197.462025</td>\n",
       "      <td>75.814125</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>106.457100</td>\n",
       "      <td>0.982200</td>\n",
       "      <td>9153.000000</td>\n",
       "      <td>0.727800</td>\n",
       "      <td>3.228700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>115.065075</td>\n",
       "      <td>65.174200</td>\n",
       "      <td>63.076825</td>\n",
       "      <td>105.592450</td>\n",
       "      <td>68.011800</td>\n",
       "      <td>63.734000</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21019.000000</td>\n",
       "      <td>593.698000</td>\n",
       "      <td>255.647200</td>\n",
       "      <td>113.441100</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>163.591600</td>\n",
       "      <td>0.992100</td>\n",
       "      <td>21633.000000</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>6.179500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>126.265100</td>\n",
       "      <td>67.459000</td>\n",
       "      <td>70.284000</td>\n",
       "      <td>116.287300</td>\n",
       "      <td>73.424700</td>\n",
       "      <td>66.539100</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.530200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AREA     PERIMETER    MAJOR_AXIS    MINOR_AXIS  ECCENTRICITY  \\\n",
       "count  75000.000000  75000.000000  75000.000000  75000.000000  75000.000000   \n",
       "mean    8379.197507    378.169453    161.805540     66.829335      0.886077   \n",
       "std     3119.209274     70.597008     36.461005     16.689269      0.071906   \n",
       "min     3929.000000    261.040000     96.968300     34.673000      0.627700   \n",
       "25%     6259.000000    316.431500    132.623500     49.650200      0.846100   \n",
       "50%     7345.000000    351.261000    149.343950     69.183900      0.885600   \n",
       "75%     8901.000000    444.986000    197.462025     75.814125      0.950800   \n",
       "max    21019.000000    593.698000    255.647200    113.441100      0.986800   \n",
       "\n",
       "            EQDIASQ      SOLIDITY   CONVEX_AREA        EXTENT  ASPECT_RATIO  \\\n",
       "count  75000.000000  75000.000000  75000.000000  75000.000000  75000.000000   \n",
       "mean     101.731251      0.975896   8584.862320      0.633226      2.597063   \n",
       "std       17.874070      0.007966   3189.298025      0.123795      0.968982   \n",
       "min       70.728800      0.877500   4032.000000      0.278800      1.284500   \n",
       "25%       89.270400      0.970900   6385.000000      0.561000      1.876100   \n",
       "50%       96.705500      0.976400   7532.000000      0.655800      2.153200   \n",
       "75%      106.457100      0.982200   9153.000000      0.727800      3.228700   \n",
       "max      163.591600      0.992100  21633.000000      0.901700      6.179500   \n",
       "\n",
       "       ...     ALLdaub4V     ALLdaub4L     ALLdaub4a     ALLdaub4b  \\\n",
       "count  ...  75000.000000  75000.000000  75000.000000  75000.000000   \n",
       "mean   ...      0.448960    111.088252     64.379443     61.461457   \n",
       "std    ...      0.021736      5.904854      1.175616      2.435635   \n",
       "min    ...      0.313900     82.300600     59.137900     53.653800   \n",
       "25%    ...      0.434200    106.632900     63.883800     59.465575   \n",
       "50%    ...      0.451600    110.770700     64.419350     61.424400   \n",
       "75%    ...      0.466100    115.065075     65.174200     63.076825   \n",
       "max    ...      0.495100    126.265100     67.459000     70.284000   \n",
       "\n",
       "          ALLdaub4Y    ALLdaub4Cb    ALLdaub4Cr    ALLdaub4XX    ALLdaub4YY  \\\n",
       "count  75000.000000  75000.000000  75000.000000  75000.000000  75000.000000   \n",
       "mean     101.925425     66.240541     63.202088      0.341944      0.357058   \n",
       "std        5.436861      2.159109      1.174976      0.041921      0.047139   \n",
       "min       75.191800     58.323800     57.363400      0.159700      0.169000   \n",
       "25%       97.834400     64.842000     63.052800      0.309900      0.320900   \n",
       "50%      101.683700     66.291600     63.522050      0.340100      0.353300   \n",
       "75%      105.592450     68.011800     63.734000      0.370300      0.387900   \n",
       "max      116.287300     73.424700     66.539100      0.463900      0.488600   \n",
       "\n",
       "         ALLdaub4ZZ  \n",
       "count  75000.000000  \n",
       "mean       0.421176  \n",
       "std        0.043137  \n",
       "min        0.191800  \n",
       "25%        0.391200  \n",
       "50%        0.424200  \n",
       "75%        0.454700  \n",
       "max        0.530200  \n",
       "\n",
       "[8 rows x 106 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44be88a6-6d31-454f-bfe8-91a0b277bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f82cd5-e094-4560-a546-67575be0007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f14884-4361-4576-b260-fa86e4b5a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df = np.array(df)\n",
    "df = pd.DataFrame(df)\n",
    "X = df.drop(columns = [106])\n",
    "y = df[106]\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a576792-2434-4582-bbcb-3a9aca0264b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "MLP: Acc=0.9991, Err=0.0009, Prec=0.9991, Rec=0.9991, F1=0.9991, Kappa=0.9988\n",
      "Random Forest: Acc=0.9981, Err=0.0019, Prec=0.9981, Rec=0.9981, F1=0.9981, Kappa=0.9977\n",
      "SVM: Acc=0.9992, Err=0.0008, Prec=0.9992, Rec=0.9992, F1=0.9992, Kappa=0.9990\n",
      "KNN: Acc=0.9976, Err=0.0024, Prec=0.9976, Rec=0.9976, F1=0.9976, Kappa=0.9970\n",
      "Logistic Regression: Acc=0.9984, Err=0.0016, Prec=0.9984, Rec=0.9984, F1=0.9984, Kappa=0.9980\n",
      "Decision Tree: Acc=0.9948, Err=0.0052, Prec=0.9948, Rec=0.9948, F1=0.9948, Kappa=0.9935\n",
      "--------------------------------------------------\n",
      "Fold 2 :\n",
      "MLP: Acc=0.9984, Err=0.0016, Prec=0.9984, Rec=0.9984, F1=0.9984, Kappa=0.9980\n",
      "Random Forest: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "SVM: Acc=0.9991, Err=0.0009, Prec=0.9991, Rec=0.9991, F1=0.9991, Kappa=0.9988\n",
      "KNN: Acc=0.9972, Err=0.0028, Prec=0.9972, Rec=0.9972, F1=0.9972, Kappa=0.9965\n",
      "Logistic Regression: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "Decision Tree: Acc=0.9972, Err=0.0028, Prec=0.9972, Rec=0.9972, F1=0.9972, Kappa=0.9965\n",
      "--------------------------------------------------\n",
      "Fold 3 :\n",
      "MLP: Acc=0.9987, Err=0.0013, Prec=0.9987, Rec=0.9987, F1=0.9987, Kappa=0.9983\n",
      "Random Forest: Acc=0.9989, Err=0.0011, Prec=0.9989, Rec=0.9989, F1=0.9989, Kappa=0.9987\n",
      "SVM: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "KNN: Acc=0.9976, Err=0.0024, Prec=0.9976, Rec=0.9976, F1=0.9976, Kappa=0.9970\n",
      "Logistic Regression: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "Decision Tree: Acc=0.9940, Err=0.0060, Prec=0.9940, Rec=0.9940, F1=0.9940, Kappa=0.9925\n",
      "--------------------------------------------------\n",
      "Fold 4 :\n",
      "MLP: Acc=0.9983, Err=0.0017, Prec=0.9983, Rec=0.9983, F1=0.9983, Kappa=0.9978\n",
      "Random Forest: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "SVM: Acc=0.9987, Err=0.0013, Prec=0.9987, Rec=0.9987, F1=0.9987, Kappa=0.9983\n",
      "KNN: Acc=0.9976, Err=0.0024, Prec=0.9976, Rec=0.9976, F1=0.9976, Kappa=0.9970\n",
      "Logistic Regression: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "Decision Tree: Acc=0.9969, Err=0.0031, Prec=0.9969, Rec=0.9969, F1=0.9969, Kappa=0.9962\n",
      "--------------------------------------------------\n",
      "Fold 5 :\n",
      "MLP: Acc=0.9992, Err=0.0008, Prec=0.9992, Rec=0.9992, F1=0.9992, Kappa=0.9990\n",
      "Random Forest: Acc=0.9989, Err=0.0011, Prec=0.9989, Rec=0.9989, F1=0.9989, Kappa=0.9987\n",
      "SVM: Acc=0.9992, Err=0.0008, Prec=0.9992, Rec=0.9992, F1=0.9992, Kappa=0.9990\n",
      "KNN: Acc=0.9979, Err=0.0021, Prec=0.9979, Rec=0.9979, F1=0.9979, Kappa=0.9973\n",
      "Logistic Regression: Acc=0.9987, Err=0.0013, Prec=0.9987, Rec=0.9987, F1=0.9987, Kappa=0.9983\n",
      "Decision Tree: Acc=0.9973, Err=0.0027, Prec=0.9973, Rec=0.9973, F1=0.9973, Kappa=0.9967\n",
      "--------------------------------------------------\n",
      "Fold 6 :\n",
      "MLP: Acc=0.9992, Err=0.0008, Prec=0.9992, Rec=0.9992, F1=0.9992, Kappa=0.9990\n",
      "Random Forest: Acc=0.9992, Err=0.0008, Prec=0.9992, Rec=0.9992, F1=0.9992, Kappa=0.9990\n",
      "SVM: Acc=0.9989, Err=0.0011, Prec=0.9989, Rec=0.9989, F1=0.9989, Kappa=0.9987\n",
      "KNN: Acc=0.9983, Err=0.0017, Prec=0.9983, Rec=0.9983, F1=0.9983, Kappa=0.9978\n",
      "Logistic Regression: Acc=0.9987, Err=0.0013, Prec=0.9987, Rec=0.9987, F1=0.9987, Kappa=0.9983\n",
      "Decision Tree: Acc=0.9956, Err=0.0044, Prec=0.9956, Rec=0.9956, F1=0.9956, Kappa=0.9945\n",
      "--------------------------------------------------\n",
      "Fold 7 :\n",
      "MLP: Acc=0.9989, Err=0.0011, Prec=0.9989, Rec=0.9989, F1=0.9989, Kappa=0.9987\n",
      "Random Forest: Acc=0.9991, Err=0.0009, Prec=0.9991, Rec=0.9991, F1=0.9991, Kappa=0.9988\n",
      "SVM: Acc=0.9984, Err=0.0016, Prec=0.9984, Rec=0.9984, F1=0.9984, Kappa=0.9980\n",
      "KNN: Acc=0.9981, Err=0.0019, Prec=0.9981, Rec=0.9981, F1=0.9981, Kappa=0.9977\n",
      "Logistic Regression: Acc=0.9977, Err=0.0023, Prec=0.9977, Rec=0.9977, F1=0.9977, Kappa=0.9972\n",
      "Decision Tree: Acc=0.9968, Err=0.0032, Prec=0.9968, Rec=0.9968, F1=0.9968, Kappa=0.9960\n",
      "--------------------------------------------------\n",
      "Fold 8 :\n",
      "MLP: Acc=0.9991, Err=0.0009, Prec=0.9991, Rec=0.9991, F1=0.9991, Kappa=0.9988\n",
      "Random Forest: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "SVM: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "KNN: Acc=0.9981, Err=0.0019, Prec=0.9981, Rec=0.9981, F1=0.9981, Kappa=0.9977\n",
      "Logistic Regression: Acc=0.9985, Err=0.0015, Prec=0.9985, Rec=0.9985, F1=0.9985, Kappa=0.9982\n",
      "Decision Tree: Acc=0.9967, Err=0.0033, Prec=0.9967, Rec=0.9967, F1=0.9967, Kappa=0.9958\n",
      "--------------------------------------------------\n",
      "Fold 9 :\n",
      "MLP: Acc=0.9987, Err=0.0013, Prec=0.9987, Rec=0.9987, F1=0.9987, Kappa=0.9983\n",
      "Random Forest: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "SVM: Acc=0.9989, Err=0.0011, Prec=0.9989, Rec=0.9989, F1=0.9989, Kappa=0.9987\n",
      "KNN: Acc=0.9973, Err=0.0027, Prec=0.9973, Rec=0.9973, F1=0.9973, Kappa=0.9967\n",
      "Logistic Regression: Acc=0.9985, Err=0.0015, Prec=0.9985, Rec=0.9985, F1=0.9985, Kappa=0.9982\n",
      "Decision Tree: Acc=0.9961, Err=0.0039, Prec=0.9961, Rec=0.9961, F1=0.9961, Kappa=0.9952\n",
      "--------------------------------------------------\n",
      "Fold 10 :\n",
      "MLP: Acc=0.9984, Err=0.0016, Prec=0.9984, Rec=0.9984, F1=0.9984, Kappa=0.9980\n",
      "Random Forest: Acc=0.9984, Err=0.0016, Prec=0.9984, Rec=0.9984, F1=0.9984, Kappa=0.9980\n",
      "SVM: Acc=0.9988, Err=0.0012, Prec=0.9988, Rec=0.9988, F1=0.9988, Kappa=0.9985\n",
      "KNN: Acc=0.9977, Err=0.0023, Prec=0.9977, Rec=0.9977, F1=0.9977, Kappa=0.9972\n",
      "Logistic Regression: Acc=0.9984, Err=0.0016, Prec=0.9984, Rec=0.9984, F1=0.9984, Kappa=0.9980\n",
      "Decision Tree: Acc=0.9960, Err=0.0040, Prec=0.9960, Rec=0.9960, F1=0.9960, Kappa=0.9950\n",
      "--------------------------------------------------\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Model               |   Avg Acc |   Avg Error |   Avg Prec |   Avg Recall |   Avg F1 |   Avg Kappa |\n",
      "+=====================+===========+=============+============+==============+==========+=============+\n",
      "| MLP                 |    0.9988 |      0.0012 |     0.9988 |       0.9988 |   0.9988 |      0.9985 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Random Forest       |    0.9988 |      0.0012 |     0.9988 |       0.9988 |   0.9988 |      0.9985 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| SVM                 |    0.9989 |      0.0011 |     0.9989 |       0.9989 |   0.9989 |      0.9986 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| KNN                 |    0.9977 |      0.0023 |     0.9978 |       0.9977 |   0.9977 |      0.9972 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Logistic Regression |    0.9985 |      0.0015 |     0.9985 |       0.9985 |   0.9985 |      0.9982 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n",
      "| Decision Tree       |    0.9961 |      0.0039 |     0.9962 |       0.9961 |   0.9961 |      0.9952 |\n",
      "+---------------------+-----------+-------------+------------+--------------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "models = {\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(64, 32, 16, 8), activation='logistic', max_iter=10000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=10),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "model_metrics = {name: {\"Accuracy\": [], \"Error\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": [], \"Kappa\": []} for name in models.keys()}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"Fold {fold + 1} :\")\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        error = 1 - acc  # Error rate\n",
    "        prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "        model_metrics[name][\"Accuracy\"].append(acc)\n",
    "        model_metrics[name][\"Error\"].append(error)\n",
    "        model_metrics[name][\"Precision\"].append(prec)\n",
    "        model_metrics[name][\"Recall\"].append(rec)\n",
    "        model_metrics[name][\"F1-Score\"].append(f1)\n",
    "        model_metrics[name][\"Kappa\"].append(kappa)\n",
    "\n",
    "        print(f\"{name}: Acc={acc:.4f}, Err={error:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}, Kappa={kappa:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "table_data = [\n",
    "    [name, \n",
    "     f\"{np.mean(metrics['Accuracy']):.4f}\", \n",
    "     f\"{np.mean(metrics['Error']):.4f}\", \n",
    "     f\"{np.mean(metrics['Precision']):.4f}\", \n",
    "     f\"{np.mean(metrics['Recall']):.4f}\", \n",
    "     f\"{np.mean(metrics['F1-Score']):.4f}\", \n",
    "     f\"{np.mean(metrics['Kappa']):.4f}\"]\n",
    "    for name, metrics in model_metrics.items()\n",
    "]\n",
    "\n",
    "print(tabulate(table_data, headers=[\"Model\", \"Avg Acc\", \"Avg Error\", \"Avg Prec\", \"Avg Recall\", \"Avg F1\", \"Avg Kappa\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0833dc38-5c6f-43fd-acdd-b809a4c6fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 1 Completed\n",
      "--------------------------------------------------\n",
      "Fold 2 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 2 Completed\n",
      "--------------------------------------------------\n",
      "Fold 3 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 3 Completed\n",
      "--------------------------------------------------\n",
      "Fold 4 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 4 Completed\n",
      "--------------------------------------------------\n",
      "Fold 5 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 5 Completed\n",
      "--------------------------------------------------\n",
      "Fold 6 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 6 Completed\n",
      "--------------------------------------------------\n",
      "Fold 7 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 7 Completed\n",
      "--------------------------------------------------\n",
      "Fold 8 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 8 Completed\n",
      "--------------------------------------------------\n",
      "Fold 9 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 9 Completed\n",
      "--------------------------------------------------\n",
      "Fold 10 :\n",
      "MLP\n",
      "Random Forest\n",
      "SVM\n",
      "KNN\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Fold 10 Completed\n",
      "--------------------------------------------------\n",
      "   Actual Class            Algorithm  Arborio  Basmati  Ipsala  Jasmine  \\\n",
      "0       Arborio                  MLP    14965        0       0       24   \n",
      "1       Arborio        Random Forest    14970        0       0       23   \n",
      "2       Arborio                  SVM    14973        0       0       16   \n",
      "3       Arborio                  KNN    14948        0       1       43   \n",
      "4       Arborio  Logistic Regression    14971        0       0       19   \n",
      "5       Arborio        Decision Tree    14912        0       6       41   \n",
      "6       Basmati                  MLP        2    14988       0       10   \n",
      "7       Basmati        Random Forest        0    14986       0       14   \n",
      "8       Basmati                  SVM        0    14982       0       18   \n",
      "9       Basmati                  KNN        2    14962       0       36   \n",
      "10      Basmati  Logistic Regression        0    14966       0       34   \n",
      "11      Basmati        Decision Tree        0    14946       1       53   \n",
      "12       Ipsala                  MLP        0        1   14997        0   \n",
      "13       Ipsala        Random Forest        4        0   14996        0   \n",
      "14       Ipsala                  SVM        0        0   15000        0   \n",
      "15       Ipsala                  KNN        1        0   14999        0   \n",
      "16       Ipsala  Logistic Regression        0        0   15000        0   \n",
      "17       Ipsala        Decision Tree        6        0   14992        2   \n",
      "18      Jasmine                  MLP       16        6       0    14978   \n",
      "19      Jasmine        Random Forest       18        3       0    14979   \n",
      "20      Jasmine                  SVM       12       14       0    14973   \n",
      "21      Jasmine                  KNN       29        4       0    14966   \n",
      "22      Jasmine  Logistic Regression       16       21       0    14961   \n",
      "23      Jasmine        Decision Tree       39       50       4    14905   \n",
      "24    Karacadag                  MLP       18        0       0        1   \n",
      "25    Karacadag        Random Forest       22        0       0        0   \n",
      "26    Karacadag                  SVM       11        0       0        1   \n",
      "27    Karacadag                  KNN       43        0       0        1   \n",
      "28    Karacadag  Logistic Regression        8        0       0        0   \n",
      "29    Karacadag        Decision Tree       38        0       1        5   \n",
      "\n",
      "    Karacadag  \n",
      "0          11  \n",
      "1           7  \n",
      "2          11  \n",
      "3           8  \n",
      "4          10  \n",
      "5          41  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          0  \n",
      "11          0  \n",
      "12          2  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          0  \n",
      "17          0  \n",
      "18          0  \n",
      "19          0  \n",
      "20          1  \n",
      "21          1  \n",
      "22          2  \n",
      "23          2  \n",
      "24      14981  \n",
      "25      14978  \n",
      "26      14988  \n",
      "27      14956  \n",
      "28      14992  \n",
      "29      14956  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = np.unique(y)\n",
    "conf_matrix_sum = {name: np.zeros((len(labels), len(labels))) for name in models.keys()}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"Fold {fold + 1} :\")\n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        conf_matrix_sum[name] += cm\n",
    "        print(f\"{name}\")\n",
    "\n",
    "    print(f\"Fold {fold + 1} Completed\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "conf_matrix_total = {name: cm.astype(int) for name, cm in conf_matrix_sum.items()}\n",
    "\n",
    "conf_matrix_data = []\n",
    "for i, actual in enumerate(labels):\n",
    "    for name, cm in conf_matrix_total.items():\n",
    "        row = [actual, name]\n",
    "        row.extend(cm[i])\n",
    "        conf_matrix_data.append(row)\n",
    "\n",
    "columns = [\"Actual Class\", \"Algorithm\"] + list(labels)\n",
    "df_conf_matrix = pd.DataFrame(conf_matrix_data, columns=columns)\n",
    "\n",
    "print(df_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ab13e6-4ce5-4c3e-86aa-c17d22c7c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|    | Actual Class   | Algorithm           |   Arborio |   Basmati |   Ipsala |   Jasmine |   Karacadag |\n",
      "+====+================+=====================+===========+===========+==========+===========+=============+\n",
      "|  0 | Arborio        | MLP                 |     14965 |         0 |        0 |        24 |          11 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  1 | Arborio        | Random Forest       |     14970 |         0 |        0 |        23 |           7 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  2 | Arborio        | SVM                 |     14973 |         0 |        0 |        16 |          11 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  3 | Arborio        | KNN                 |     14948 |         0 |        1 |        43 |           8 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  4 | Arborio        | Logistic Regression |     14971 |         0 |        0 |        19 |          10 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  5 | Arborio        | Decision Tree       |     14912 |         0 |        6 |        41 |          41 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  6 | Basmati        | MLP                 |         2 |     14988 |        0 |        10 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  7 | Basmati        | Random Forest       |         0 |     14986 |        0 |        14 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  8 | Basmati        | SVM                 |         0 |     14982 |        0 |        18 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "|  9 | Basmati        | KNN                 |         2 |     14962 |        0 |        36 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 10 | Basmati        | Logistic Regression |         0 |     14966 |        0 |        34 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 11 | Basmati        | Decision Tree       |         0 |     14946 |        1 |        53 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 12 | Ipsala         | MLP                 |         0 |         1 |    14997 |         0 |           2 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 13 | Ipsala         | Random Forest       |         4 |         0 |    14996 |         0 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 14 | Ipsala         | SVM                 |         0 |         0 |    15000 |         0 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 15 | Ipsala         | KNN                 |         1 |         0 |    14999 |         0 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 16 | Ipsala         | Logistic Regression |         0 |         0 |    15000 |         0 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 17 | Ipsala         | Decision Tree       |         6 |         0 |    14992 |         2 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 18 | Jasmine        | MLP                 |        16 |         6 |        0 |     14978 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 19 | Jasmine        | Random Forest       |        18 |         3 |        0 |     14979 |           0 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 20 | Jasmine        | SVM                 |        12 |        14 |        0 |     14973 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 21 | Jasmine        | KNN                 |        29 |         4 |        0 |     14966 |           1 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 22 | Jasmine        | Logistic Regression |        16 |        21 |        0 |     14961 |           2 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 23 | Jasmine        | Decision Tree       |        39 |        50 |        4 |     14905 |           2 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 24 | Karacadag      | MLP                 |        18 |         0 |        0 |         1 |       14981 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 25 | Karacadag      | Random Forest       |        22 |         0 |        0 |         0 |       14978 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 26 | Karacadag      | SVM                 |        11 |         0 |        0 |         1 |       14988 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 27 | Karacadag      | KNN                 |        43 |         0 |        0 |         1 |       14956 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 28 | Karacadag      | Logistic Regression |         8 |         0 |        0 |         0 |       14992 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n",
      "| 29 | Karacadag      | Decision Tree       |        38 |         0 |        1 |         5 |       14956 |\n",
      "+----+----------------+---------------------+-----------+-----------+----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(df_conf_matrix, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c62ab-d5b3-40a3-b7a3-7a551e53d482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
